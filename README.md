# Classifica√ß√£o de Quest√µes de Vestibular

Modelo de Machine Learning para Classifica√ß√£o de Quest√µes de Vestibular

## I - Exposi√ß√£o do Problema üöÄ

Este projeto iniciou-se a partir de um problema da startup em que fa√ßo parte. Um certo momento, levantou-se a necessidade de fornecer aos nossos usu√°rios, quest√µes de vestibulares para que eles possam estudar mais e ter mais conte√∫dos para irem bem no vestibular.
Com isso, houve a necessidade de adicionar no nosso sistema, quest√µes de vestibular. Assim, criou-se um banco de dados com 120 mil quest√µes de vestibular.
Por√©m, ap√≥s validarmos os dados, identificamos que nem todos as quest√µes estavam classificadas de acordo com o assunto que elas pertenciam, o que nos daria um enorme trabalho para classific√°-las manualmente.
Assim, surgiu a ideia de implementar um modelo e trein√°-lo, a fim de classificar cada quest√£o de acordo com o assunto que essa quest√£o pertence.

### O Sistema üíª

Para que esse trabalho seja automatizado de uma forma inteligente, foi idealizado um sistema para a avalia√ß√£o de textos, com o objetivo de ler, intepretar e classificar as quest√µes de acordo com o conte√∫do de cada quest√£o.
Com isso, o modelo iniciou-se com a prepara√ß√£o e limpeza dos dados, seguido da implementa√ß√£o do bag of words, fun√ß√£o essa que tem como objetivo identificar as palavras mais recorrentes e entender se elas agregam na classifica√ß√£o das quest√µes.
Ap√≥s a implementa√ß√£o, foi validado se as palavras tinham valor sem√¢ntico para o treinamento do modelo, onde descobriu-se a necessidade de remover algumas palavras.
Assim, com essa limpeza de dados, desenvolveu-se o modelo que, em sua m√©dia, tem dado uma taxa de acerto de 74%.

## II - Importa√ß√£o dos dados üé≤

Como dito anteriormente, foi feito um banco de dados com as 120 mil quest√µes. Para o desenvolvimento da an√°lise, foram selecionados apenas quest√µes de matem√°tica.
Assim, como os dados estavam no banco do NoSQL do MongoDB, foi utilizado um framework do pr√≥prio Mongo para conectar e importar os dados para o Python.

```
client = MongoClient(config["MONGO_CONNECTION_STRING"])
database = client["revisapp"]
collection = database["questions"]

query["subjectName"] = u"matematica"

cursor = collection.find(query, projection=projection, sort=sort, limit=40000)
questoes = pd.array(list(cursor))

client.close()
```

Como apenas foi selecionado matem√°tica, houve somente a sele√ß√£o da mat√©ria em quest√£o.

## III - Prepara√ß√£o dos dados üî®

Na fase de aquisi√ß√£o das quest√µes, foi feito uma ferramenta de webscrapping para a captura das quest√µes. Assim, os dados foram recebidos e inseridos no banco no formato HTML, uma vez que pra apresenta√ß√£o, tamb√©m utilizamos a linguagem HTML.
Com isso, para uma an√°lise mais acertiva, foi necess√°rio convert√™-los em texto utilizado a biblioteca BeautifulSoup.

```
from bs4 import BeautifulSoup

for i in range(len(corpus )):
    corpus[i] = corpus[i].lower()
    corpus[i] = BeautifulSoup(corpus [i]).get_text() # transforma o HTML em texto
    corpus [i] = re.sub(r'\W',' ',corpus [i])  # remove os caracteres especiais
    corpus [i] = re.sub(r'\s+',' ',corpus [i]) # remove os caracteres especiais
    
```

Uma vez que os dados foram limpos e com seus caracteres especias removidos, foi necess√°rio fazer o processo de _Stemming_, que consiste em reduzir palavras relacionadas a uma forma m√≠nima comum, de forma que possam ser combinadas sob uma √∫nica representa√ß√£o, chamada de _stem_. Com este processo, obt√©m-se √≠ndices mais enxutos, melhorando assim a qualidade dos dados para o modelo.

Assim, foi criado uma fun√ß√£o com esse objetivo, utilizando a biblioteca _nltk.stem_.

```
from nltk.tokenize import word_tokenize
from nltk.stem import RSLPStemmer
from unidecode import unidecode

stemmer = RSLPStemmer()

def stemSentence(sentence):
    token_words = word_tokenize(sentence)
    token_words
    stem_sentence = []
    for word in token_words:
        if word not in nltk.corpus.stopwords.words('portuguese'):
            word = stemmer.stem(word)
            word = unidecode(word)
            stem_sentence.append(word)  
            stem_sentence.append(" ")
    return "".join(stem_sentence)
```

Essa fun√ß√£o criada, al√©m de fazer o _stem_, tamb√©m remove os acentos e os _stopwords_. 
Os _stopwords_ s√£o palavras que podem ser consideradas irrelevantes para o conjunto de resultados a ser exibido em uma busca realizada em uma search engine. Exemplos: as, e, os, de, para, com, sem, foi, etc..

Assim, as palavras a serem consideradas s√£o reduzidas, conforme exemplo abaixo::

```
'med centimetr lad triangul express x 1 2x x2 5 progress aritme ness ord calcul perimetr triangul ',
'sequ figur desenh malh quadricul indic tre prim etap form fract cad quadr dess malh are 1 cm2 ',
'consider med metr lad triangul progress geometr ness ord express x 1 2x x2 corret afirm perimetr dess triangul med ',
'sequ infinit triangul equilater pod ser constru inscrev triangul dentr outr part prim ',
'consid triangul i ii iii caracter abaix atraves med lad triangul i 9 12 15 triangul ii 5 12 13 triangul iii 5 7 9 qual triangul retangul med lad progress aritme ',
'sequ x 1 2x 1 5x 3 constitu progress aritme tre term cuj val represent med centimetr lad triangul dess mod corret afirm perimetr dess triangul centimetr igual ',
```

Como parte do processo de processamento de texto, √© necess√°rio verificar quais palavras s√£o as mais frequentes, para que sejam usadas posteriormente.
Assim, foi utilizado a fun√ß√£o "word_tokenize", que pega uma senten√ßa e separa os dados em posi√ß√µes de uma lista.

```
wordfreq = {}
for sentence in corpus:
    tokens = nltk.word_tokenize(sentence)
    for token in tokens:
        if token not in wordfreq.keys():
            wordfreq[token] = 1
        else:
            wordfreq[token] += 1
```

Agora, ordena-se essa lista considerando aqueles termos que aparecem com mais frequ√™ncia. No nosso caso, selecionamos as 150 palavras mais frequ√™ntes.

```
import heapq

MOST_FREQUENT_NUMBER = 150

most_freq = heapq.nlargest(MOST_FREQUENT_NUMBER, wordfreq, key=wordfreq.get)
```

O ultimo passo √© criar o saco de palavras transcrevendo cada documento para uma informa√ß√£o booleana dizendo se cada palavra do saco de palavras est√° presente ou n√£o no documento. Se a palavra estiver na senten√ßa, coloca 1, se n√£o, 0.

```
sentence_vectors = []
for sentence in corpus:
    sentence_tokens = nltk.word_tokenize(sentence)

    sent_vec = []
    for token in most_freq:
        if token in sentence_tokens:
            sent_vec.append(1)
        else:
            sent_vec.append(0)
    sentence_vectors.append(sent_vec)

sentence_vectors = np.array(sentence_vectors)
```

Uma vez que o modelo foi desenhado para classificar os assuntos de matem√°tica, foi necess√°rio separar essa √∫nica classifica√ß√£o "conjuntas" em diversas classifica√ß√µes. Assim, levantou-se todas as possibilidades de assuntos existentes no banco de quest√µes de matem√°tica, criando assim um _array_ com 81 assuntos distintos.

```
subjects = ['√Ålgebra', 'Probabilidade e estat√≠stica', 'N√∫meros', 'No√ß√µes de l√≥gica',
            'No√ß√µes de L√≥gica Matem√°tica', 'Matem√°tica Financeira', 'Grandezas e medidas', 'Raz√£o e Propor√ß√£o',
            'Geometria', 'Estat√≠stica', 'Determinantes', '√Ålgebra linear', 'An√°lise Combinat√≥ria', 'Arcos na Circunfer√™ncia',
            '√Årea e Per√≠metro das Figuras Planas', 'Aritm√©tica', 'Arranjo', 'C√°lculo diferencial integral', 'Cilindros', 'Circunfer√™ncia',
            'Circunfer√™ncia e C√≠rculo', 'Combina√ß√£o', 'Comprimento', 'Volume', 'Cones', 'Esfera', 'Congru√™ncia de Tri√¢ngulos',
            'C√¥nicas', 'Conjuntos', 'Conjuntos Fun√ß√£o', 'Decimal', 'Equa√ß√£o do Primeiro Grau', 'Equa√ß√£o do Segundo Grau',
            'Equa√ß√µes', 'Equa√ß√µes polinomiais', 'Equa√ß√µes polinomiais Exponenciais', 'Esfera', 'Express√µes alg√©bricas', 'Express√µes alg√©bricas',
            'Fatorial', 'Fun√ß√£o', 'Fun√ß√£o Exponencial', 'Fun√ß√£o Logar√≠tmica', 'Raz√µes e propor√ß√µes',
            'Fun√ß√£o Quadr√°tica', 'Fun√ß√£o Trigonometria', 'Fun√ß√µes Definidas por V√°rias Senten√ßas', 'Fun√ß√µes Trigonom√©tricas', 'Fundamentos',
            'Geometria anal√≠tica', 'Geometria espacial', 'Geometria plana', 'Gr√°ficos', 'Inequa√ß√£o do Segundo Grau', 'Inequa√ß√µes', 'Inequa√ß√µes polinomiais',
            'Inequa√ß√µes polinomiais', 'Juros Compostos', 'Juros Simples', 'L√≥gica matem√°tica', 'Prismas', 'M√©dias',
            'Ponderada', 'Porcentagem', 'Probabilidade', 'M√∫ltiplos e Divisores', 'Nota√ß√£o cient√≠fica',
            'Outros', 'Permuta√ß√£o', 'Pir√¢mides', 'Pol√≠gonos', 'Princ√≠pio Fundamental da Contagem', 'Prismas', 
            'Problemas sobre as 4 opera√ß√µes', 'Raz√µes Trigonom√©tricas no Tri√¢ngulo Ret√¢ngulo', 'Rela√ß√µes M√©tricas do Tri√¢ngulo Ret√¢ngulo',
            'Rela√ß√µes M√©tricas em Tri√¢ngulos Quaisquer', 'Reta', 'Retas e Planos', 'Sequ√™ncias', 'Sistema de Numera√ß√£o e M√©trico', 'Superf√≠cie Poli√©drica e Poliedros',
            'Tempo', 'Trigonometria', 'Troncos']
```

Como feito nas quest√µes, o _output_ foi dividido igual o bag of words implementado no enunciado das quest√µes. Para o treinamento do modelo, foi colocado 1 ou 0 se o assunto pertencia √†quela quest√£o ou n√£o.

```
df = documents
for index, document in df.iterrows():
    i = 0
    for subject in subjects:
        i += 1
        column_name = "tag_"+str(i)
        if (subject in document["level_2"]) or (subject in document["level_3"]):
            df.loc[index, subject] = 1
        else:
            df.loc[index, subject] = 0
```

## IV - An√°lise explorat√≥ria ü§ì

A an√°lise explorat√≥ria deve ser feita antes de qualquer tipo de modelagem em si. Esse passo √© essencial entender a natureza dos dados e tamb√©m para resumir suas caracter√≠sticas principais.
Para isso, foi feito a distribui√ß√£o dos dados atrav√©s da plotagem de histogramas.

Assim, algumas quest√µes foram levantadas para que os dados nos respondessem, conforme a seguir.

### Quais s√£o os assuntos mais recorrentes?

Foi verificado os assuntos de matem√°tica mais recorrentes, para entender a distribui√ß√£o dos valores.

![plot](./images/fig_subject_count.png)

Verificou-se que os assuntos de √Ålgebra e Geometria dominavam as quest√µes. S√£o os assuntos mais recorrentes em matem√°tica nos vestibulares. Ap√≥s isso, os assuntos de Geometria Espacial, Fun√ß√µes, Probabilidade tiveram menor peso.

### Quais s√£o as palavras mais recorrentes?

Foi validado quais eram as palavras mais recorrentes, com o objetivo de validar se n√£o haviam palavras que n√£o deveriam estar presentes.

![plot](./images/fig_word_count.png)

Primeiramente, na valida√ß√£o inicial, identificou-se que haviam muitas algaritmos usados em matem√°tica como "palavras" recorrentes, como exemplo o _x_, _y_, _i_, etc..
Assim, foi necess√°rio voltar ao passo da limpeza dos dados para que esses algaritmos fossem removidos, removendo assim suas frequencias da nossa lista de palavras mais frequentes.

```
for word in wordfreq:
    if (len(word)) < 2: # removendo vari√°veis (exemplo: x, y, etc..)
        wordfreq[word] = 0
    if (word.isnumeric()):  # removendo "n√∫meros" 
        wordfreq[word] = 0
```
Assim, foi criado uma nuvem de palavra para mostrar quais as palavras mais recorrentes, e foi verificado que todas as mais recorrentes eram palavras v√°lidas, com significado sem√¢ntico.

![plot](./images/fig_wordcloud.png)

Com essa limpeza de dados que a an√°lise explorat√≥ria nos apontou a necessidade, tivemos uma melhora consider√°vel na taxa de acerto das predi√ß√µes, saindo de uma m√©dia de 55% de acerto para aproximadamente 74%.

## V - Modelagem üî•

O modelo proposto foi desenhado de acordo com a classifica√ß√£o j√° existente no banco de dados. As classifica√ß√µes existentes consistiam na concatena√ß√£o dos assuntos em que a quest√£o estava envolvida.

Exemplos de classifica√ß√£o:
* √Ålgebra Matem√°tica Financeira N√∫meros
* No√ß√µes de l√≥gica No√ß√µes de L√≥gica Matem√°tica
* √Ålgebra Grandezas e medidas Raz√£o e Propor√ß√£o

Pode-se observar que h√° diversos assuntos para uma quest√£o √∫nica, o que nos mostra que esse √© um problema com multiplas sa√≠das/resultados.


### testes de classificadores

Como o problema consiste em uma classifica√ß√£o de multiplas sa√≠das, foi utilizado a classe _MultiOutputClassifier_ da biblioteca _sklearn_.
Para que essa classe funcione corretamente, √© necess√°rio escolher um _estimator_, que, nesse caso, utilizamos o _RandomForestClassifier_.

O nome (Classificador Floresta Aleat√≥ria) explica muito bem o funcionamento do algoritmo, que ir√° criar muitas √°rvores de decis√£o, de maneira aleat√≥ria, formando o que podemos enxergar como uma floresta, onde cada √°rvore ser√° utilizada na escolha do resultado final.

Durante o processo de contru√ß√£o do modelo, tambpem foi testado o _KNeighborsClassifier_ e o _MLPClassifier_, por√©m com resultados inferiores ao _RandomForestClassifier_.

```
clf = MultiOutputClassifier(RandomForestClassifier(max_depth=24, min_samples_leaf=6))
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
```

Agora, √© feito o teste para avaliar se o treinamento deu certo.
Crio-se um vetor (hits) que me mostra quais predi√ß√µes foram corretas. Como se trata de um problema de multiplas sa√≠das, foi avaliado se pelo menos 1 assunto foi predito corretamente.
No in√≠cio, foi testado apenas as classifica√ß√µes que bateram 100% com as classifica√ß√µes de teste, por√©m, os valores eram muito baixos e n√£o fez sentido ao problema que t√≠nhamos.
Nesse caso e aplicado ao problema que t√≠nhamos, tendo apenas uma ou mais classifica√ß√µes corretas, ja nos atendia e resolvia o problema.

```
hits = np.any((y_pred + y_test) > 1, axis=1)
print("taxa de acerto: ", round(hits.sum()/len(hits)*100,2), "%")
```

Assim, ap√≥s in√∫meros treinos e respostas do modelo, observou-se que temos uma taxa de acerto m√©dia de 74%.

Tamb√©m, foi feito o plot dos valores do modelo, com o objetivo de entender como ficou a distribui√ß√£o dos acertos. 

![plot](./images/fig_model_output.png)

Observando os gr√°ficos de respostas acima, √© possivel concluir que, aproximadamente 26% das quest√µes tiveram menos de 0 acertos.
Aproximadamente 16% das quest√µes tiveram 100% de acerto na predi√ß√£o do modelo.
Como o o problema em quest√£o era apontar os assuntos existente na quest√£o, considerou-se apenas as predi√ß√µes com pelo menos 1 acerto, totalizando assim 74% de acertividade.

## VI - Fechamento üîí

Inicialmente, foi desenhado um modelo para a clusteriza√ß√£o das quest√µes, conforme desenho a seguir:

![plot](./images/fig_solution_v1.jpeg)

Por√©m, ap√≥s o melhor conhecimento dos dados, foi identificado que o modelo idealizado n√£o funcionaria para a solu√ß√£o. Assim, durante o trajeto do projeto, foi alterado a solu√ß√£o.
Da implementa√ß√£o, foi extra√≠do um modelo que ser√° utilizado no aplicativo RevisApp. A id√©ia √© utilizar o modelo para otimizar os estudos dos usu√°rios do _app_ atrav√©s de uma funcionalidade ainda em implementa√ß√£o. Com isso, poderemos indicar aos nossos usu√°rios quais assuntos ele tem mais dificuldade e, consequentemente, quais precisam ser estudados com mais intensidade, sugerindo assim o conte√∫ido e quest√µes similares dos assuntos em d√©ficit de conhecimento.
A implementa√ß√£o deste modelo foi desafiador. A falta de vis√£o matem√°tica dos dados atrapalhou um pouco o desenvolvimento do modelo. A mentoria realizada pela equipe de profissionais da awari foi fundamental em todo o processo de desenvolvimento, monstrando onde estavam os gaps do meu conhecimento e onde eu poderia melhorar para chegar no resultado final.
Tamb√©m, conclui-se que √© necess√°rio entender os seus dados para implementa√ß√£o do modelo. Durante a implementa√ß√£o, foi percebido que o mesmo modelo necessitar√° de ajustes e adapta√ß√µes para outras mat√©rias.
A limpeza feita para matem√°tica n√£o √© a mesma limpeza de dados a ser feita para biologia, por exemplo.

## VII - Refer√™ncias üïÆ

Natural Language Toolkit:
 - https://www.nltk.org/

Bag of Words:
 - https://www.mygreatlearning.com/blog/bag-of-words/

Stemming and Lemmatization in Python:
 - https://www.datacamp.com/community/tutorials/stemming-lemmatization-python

Splitting data:
- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html

Valida√ß√£o cruzada:
- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html

Multi target classification:
 - https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html

---
‚å®Ô∏è por [Mauricio Freitas](https://github.com/msfreit)